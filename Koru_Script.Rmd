---
title: "R Markdown"
author: "Vena"
date: "2022-12-19"
output: html_document
---

#Data Visualization

```{r}
library(tidyverse)
library(dplyr)
library(palmerpenguins)
library(ggthemes)
library(ggplot2)
library(gapminder)
library(forcats)
library(stringr)
```

#####vs = Its the vein scaling, which represents the area of the site vd = Vein density p_width = petiole width b_area = box area

```{r}
library(readxl)
lvd_draft2 <- read_excel("lvd_draft.xlsx", 
    sheet = "trials", col_types = c("text", 
        "text", "text", "numeric", "numeric", 
        "numeric"))
#####The petiole metric is included here
###I have manipulated the Merkhofer et 2015 without the conversion
vs <- lvd_draft %>% 
  mutate(length = vein_length*10,
         p_width = petiole_width*10,
         b_area = box_area*100,
         vd = length/b_area) %>% 
  group_by(field_name, morphotype, petiole_width) %>%
  mutate(mean_vd = mean(vd)) %>% 
  ungroup() %>% 
  mutate(vs = (((10^(1.96-2.04*log10(mean_vd*10)))*100)),
         ln_vs = log(vs), p.m = (p_width^2)/vs)

if (!requireNamespace("here")) install.packages("here")
library("here")
library(openxlsx)
write.xlsx (vs, here("vs.xls"))

#######Size Classes

sizes <- lvd_draft %>% 
  mutate(length = vein_length*10,
         p_width = petiole_width*10,
         b_area = box_area*100,
         vd = length/b_area) %>% 
  group_by(field_name, morphotype, petiole_width) %>%
  mutate(mean_vd = mean(vd)) %>% 
  ungroup() %>% 
  mutate(vs = (((10^(1.96-2.04*log10(mean_vd*10)))*100)),
         ln_vs = log(vs), p.m = (p_width^2)/vs)%>% 
  select(field_name, morphotype, vs) %>% 
  filter(field_name == "TIND-2023" ) %>% 
  arrange(-vs)
 
###Site MAP 
  MAP <- vs %>% 
  group_by(morphotype) %>% 
    summarise( mean_morpho = mean(ln_vs, na.rm = T)) %>% 
  summarise(site_mean2 = mean(mean_morpho)) %>% 
  mutate(map = exp((0.548*site_mean2)+ 0.768))

```

####################################
########LMA reconstructions###########
########################################

```{r}
###Coefficients for calculating 95% prediction intervals, reported in Royer et al 2007, Table 2
s <- 0.032237
n <- 667
X <- -3.011
Ex2 <- 182.1
t <- 1.964

m <- unique(sp.m$morphotype)
summary.table <- data.frame()

#Loop
for (i in 1:length(m)) {

  #isolate morphotype 
  temp <- sp.m[sp.m$morphotype == m[i],]
  
  ###Royer's linear regression
  mean.pm <- temp$p.m
  mean.pm.log <- log10(mean.pm) #log transform it
  log.est.lma <- 3.070 + (0.382 * mean.pm.log) #estimate your LMA in log scale
  est.lma <- 10^(log.est.lma) #back transform to linear scale
  
  #Sample size of our own data
  k <- temp$k
    
  #Calculate PI
  upper.PI <- 10^(log.est.lma + sqrt( s * ( (1/k) + (1/n) + (((mean.pm.log -  X)^2) / Ex2)))*t)
  lower.PI <- 10^(log.est.lma - sqrt( s * ( (1/k) + (1/n) + (((mean.pm.log -  X)^2) / Ex2)))*t)
  
  #temp summary table
  temp.summary <- data.frame(morphotype=m[i], est.lma.R=est.lma, upper.PI.R=upper.PI, lower.PI.R=lower.PI)
  
  #bind to dataframe outside of loop
  summary.table <- rbind(summary.table, temp.summary)
  
}

summary_lowe <- merge(sp.m, summary.table, by = "morphotype")
library(openxlsx)
 # Specify the file path where you want to save the Excel file
file_path <- "summary_table.xlsx"

# Write the summary table dataframe to an Excel file
write.xlsx(summary_lowe, file_path, rowNames = FALSE)

# Message to confirm the export
cat("Summary table exported to", file_path, "\n")

koru<- modern_lma <- read_excel("modern_lma.xlsx", 
    sheet = "koru", col_types = c("text", 
        "numeric", "numeric", "text"))
  koru %>%
    ggplot(aes(habit,lma), fill = morphotype) +
    geom_boxplot() +
    scale_y_continuous(limits = c(0, 300)) +
    theme_base()
  
```

###site variance PI

```{r}
 ###Coefficients for calculating 95% prediction intervals, reported in Lowe et al 2024, Table 3
  s <- 0.1713672
  n <- 70
  X <- -5.97104
  Ex2 <- 5.085184
  t <- 1.995469
  
mean.pm.log <- log10(site.v.r3) #log transform it
    log.est.lma <- 5.028 + (0.302 * mean.pm.log) #estimate your LMA in log scale
    est.lma <- 10^(log.est.lma) #back transform to linear scale
    
    #Calculate PI
    upper.PI <- 10^(log.est.lma + sqrt( s * ( (1/k) + (1/n) + (((mean.pm.log -  X)^2) / Ex2)))*t)
    lower.PI <- 10^(log.est.lma - sqrt( s * ( (1/k) + (1/n) + (((mean.pm.log -  X)^2) / Ex2)))*t)
    
summary_r3 <- data.frame(lma=est.lma, upper.PI=upper.PI, lower.PI=lower.PI)
summary_variance <- rbind(summary_koru, summary_kiahera, summary_r3)
rownames(summary_variance) <- paste0("Site", 1:nrow(summary_variance))

```

```{r}
site_level<- modern_lma <- read_excel("modern_lma.xlsx", 
    sheet = "site_level", col_types = c("text", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric"))
site_level %>%
  ggplot(aes(var, lma, color = site)) +
  geom_point() +
  geom_errorbar(aes(ymin = lma - lower.PI.m, ymax = lma + upper.PI.m), width = 0.1) +
  geom_errorbarh(aes(xmin = var - lower.PI.v, xmax = var + upper.PI.v), height = 0.1) +
  theme_clean()+
  coord_flip()

geom_errorbar(aes(ymin = est.lma.R - lower.PI.R,
                    ymax = est.lma.R + upper.PI.R),
                position = position_dodge(width = 0.25),
                width = 1)
```

#####Leaf_Sizes distribution

```{r}
library(ggplot2)
library(hrbrthemes)

ggplot(vs, aes(x = ln_vs, na.rm = TRUE)) +
  geom_histogram(binwidth = 2, position = "dodge") +
  theme_clean() + 
  labs(x = "Species Mean Area ln mm^2",
       y = "Species Count") 

# Assuming your dataframe is named 'vs'
  leaf_sizes <- vs %>%
  mutate(ln_vs_class = if_else(ln_vs > 7.6, "large", "small"))
 
    ggplot(leaf_sizes, aes(x = ln_vs, fill = ln_vs_class)) +
  geom_histogram(binwidth = 2, position = "identity", alpha = 1) +
  scale_fill_manual(values = c("large" = "gray", "small" = "black")) +
  labs(x = "ln_vs",
       y = "Count",
       fill = "Category") +
   guides(fill = "none") +
  theme_clean()

  ggsave("leaf_sizes.pdf", plot = leaf_sizes, width = 8, height = 6)


```

```{r}
#sum <- modern_lma %>% 
 # (sum_kibwezi = sum(kibwezi))
#percent <- mutate(kib = (kibwezi/sum_kibwezi)*100)
```

######Comparative_MAP

```{r}
library(readxl)
modern_lma <- read_excel("modern_lma.xlsx", 
    sheet = "MAP", col_types = c("text", 
        "numeric", "numeric", "numeric"))
 modern_lma %>%
  rename("method" = "Method") %>%
  mutate( koru = Koru*10,
          p_error = p_error*10,
          n_error = n_error*10) %>% 
  ggplot(aes(method, koru, shape = method)) +
  geom_point(size = 5) +
  geom_errorbar(aes(ymin = koru-n_error,
                    ymax = koru+p_error),
                #position = position_dodge(0),
                width = 0.5) +
  scale_y_continuous(limits = c(0, 4000)) +
  theme_clean()
 
#ggsave(modern_lma = "map_fossil.png",map_fossil,
      # width=5,height=4,units="in")

```

#######comparative_MAT

```{r}
modern_lma <- read_excel("modern_lma.xlsx", 
    sheet = "MAT", col_types = c("text", 
        "numeric", "numeric", "numeric"))
 modern_lma %>%
  rename("method" = "Method", "koru" = "Koru") %>%
  ggplot(aes(method, koru, shape = method)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = koru-n_error,
                    ymax = koru+p_error),
                #position = position_dodge(0),
                width = 0.3) +
  scale_y_continuous(limits = c(0, 30)) +
  theme_clean()
```


```

LMA_box_plot

```{r}
summary.table %>%
  drop_na(morphotype) %>% 
  ggplot(aes(x = morphotype, y = est.lma.R)) +
  geom_point() +
  geom_errorbar(aes(ymin = est.lma.R - lower.PI.R,
                    ymax = est.lma.R + upper.PI.R),
                position = position_dodge(width = 0.25),
                width = 1) +
  labs(title = "",
       x = "Morphotype",
       y = "LMA")+
  theme_clean()

```

Modern_lma_site level(Lowe et al., 2025)

```{r}
modern_lma <- read_excel("modern_lma.xlsx", 
    sheet = "lma", col_types = c("text", 
        "numeric", "numeric", "text"))
modern_lma$habit <- as.factor(modern_lma$habit)
modern_lma %>%
  filter(!is.na(habit) & habit != "") %>% 
  ggplot(aes(y = lma, fill = habit, na.rm = T)) +
  geom_histogram(bins = 20, position = "dodge") +
  scale_fill_manual(values = c("black", "gray"))+
  scale_y_continuous(limits = c(0, 500)) +
  guides(fill = FALSE) +
  labs(title = "",
       x = "Species count (extant)",
       y = "Leaf mass per area (g/m2)") +
  theme_clean()

```  

####t-test

```{r}

modern_lma$Method <- as.factor(modern_lma$Method)


# Kruskal-Wallis test
result_kruskal <- kruskal.test(Koru ~ Method, data = modern_lma)
soil_krustal <- kruskal.test(cao ~ sample, data = soils)
site_krustal <- kruskal.test(var ~ site, data = site_level)
# ANOVA test
result_anova <- aov(Koru ~ Method, data = modern_lma)
summary(result_anova)

# Fit the ANOVA model
result_anova <- aov(Koru ~ Method, data = modern_lma)

# Get the summary of the ANOVA
summary(result_anova)

# Calculate R-squared
total_ss <- sum((modern_lma$Koru - mean(modern_lma$Koru))^2)
residual_ss <- sum(residuals(result_anova)^2)
r_squared <- 1 - (residual_ss / total_ss)

# Print the R-squared value
print(r_squared)
```

CO2 Trend

#Read data from CO2-PIP proxy dataset (MontaÃ±ez et al., 2024)

```{r}
library(readxl)
modern_lma <- read_excel("modern_lma.xlsx", 
    sheet = "stomata", col_types = c("numeric", 
        "numeric", "numeric", "numeric", 
        "skip"))

modern_lma %>%
  filter(age >= 14 & age <= 22) %>% 
  ggplot(aes(x = age, y = ppm), na.rm = T) +
  geom_point()+
  geom_line() +
  coord_flip() +
  theme_classic() +
  #scale_y_continuous(breaks = seq(0, max(modern_lma$age), by = 1)) +
  geom_ribbon(aes(ymin = ppm-ppm_low, 
                  ymax = ppm+ppm_high),
                  alpha = 0.3)
  
```

Diversity Indices

```{r}
# Install and load the vegan package if not already installed
if (!requireNamespace("vegan", quietly = TRUE)) {
  install.packages("vegan")
}
library(vegan)

library(readxl)
modern_lma <- read_excel("modern_lma.xlsx", 
    sheet = "inext", col_types = c("skip", 
        "numeric", "numeric", "numeric"))

#transposed
transposed <- t(modern_lma)

# Calculate Fisher's alpha diversity
shannon_diversity <- diversity(transposed, index = "shannon")

# Convert Shannon diversity to Fisher's alpha
fisher_alpha <- exp(shannon_diversity) - 1

# Print the result
print(fisher_alpha)

################ Function to calculate Margalef's diversity index
margalef_diversity <- function(S, N) {
  D <- (S - 1) / log(N)
  return(D)
}

# Function to perform bootstrapping
bootstrap_margalef_diversity <- function(data, n_bootstraps = 10000) {
  n <- length(data)
  N <- sum(data)
  bootstrapped_values <- replicate(n_bootstraps, {
    sample_data <- sample(data, replace = TRUE)
    S <- sum(sample_data > 0)
    return(margalef_diversity(S, N))
  })
  return(bootstrapped_values)
}

# Call the function with your richness data
bootstrapped_values <- bootstrap_margalef_diversity(modern_lma$combined)

# Calculate the 95% confidence interval
ci <- quantile(bootstrapped_values, c(0.025, 0.975))

# Print the results
cat("Margalef's Diversity Estimate:", mean(bootstrapped_values), "\n")
cat("95% Confidence Interval:", ci[1], "-", ci[2], "\n")

#########Pielou's Evenness

library(vegan)

# Function to calculate Pielou's evenness
pielou_evenness <- function(x) {
  H <- diversity(x, index = "shannon")
  S <- specnumber(x)
  J <- H/log(S)
  return(J)
}

# Function to perform bootstrapping
bootstrap_pielou_evenness <- function(data, n_bootstraps = 10000) {
  n <- length(data)
  bootstrapped_values <- replicate(n_bootstraps, {
    sample_data <- sample(data, replace = TRUE)
    return(pielou_evenness(sample_data))
  })
  return(bootstrapped_values)
}

# Call the function with your abundance data

bootstrapped_values <- bootstrap_pielou_evenness(modern_lma$combined)

# Calculate the 95% confidence interval
ci <- quantile(bootstrapped_values, c(0.025, 0.975))

# Print the results
cat("Pielou's Evenness Estimate:", mean(bootstrapped_values), "\n")
cat("95% Confidence Interval:", ci[1], "-", ci[2], "\n")




#########Berger_parker_bootstrap
# Function to calculate Berger-Parker dominance index
berger_parker_index <- function(x) {
  max_abundance <- max(x)
  dominance <- max_abundance / sum(x)
  return(dominance)
}

# Function to perform bootstrapping
bootstrap_berger_parker <- function(data, n_bootstraps = 10000) {
  n <- length(data)
  bootstrapped_values <- replicate(n_bootstraps, {
    sample_data <- sample(data, replace = TRUE)
    return(berger_parker_index(sample_data))
  })
  return(bootstrapped_values)
}


# Call the function with your abundance data
bootstrapped_values <- bootstrap_berger_parker(modern_lma$combined)

# Calculate the 95% confidence interval
ci <- quantile(bootstrapped_values, c(0.025, 0.975))

# Print the results
cat("Berger-Parker Dominance Estimate:", mean(bootstrapped_values), "\n")
cat("95% Confidence Interval:", ci[1], "-", ci[2], "\n")


####################Bray_Curtis
bray_curtis <- vegdist(modern_lma, method = "bray")
print(bray_curtis)

```

Whittaker Biome plots
```{r}
install.packages("devtools")
library(devtools)
devtools::install_github("valentinitnelav/plotbiomes") 
library(plotbiomes)

#########
 koru_biome <- whittaker_base_plot() +
  geom_point(data = modern_lma,
             aes(x = temperature,
                 y = precipitation,
                 colour = sites),
             shape = 16,
             size  = 5) +
    scale_color_manual(name   = "sites",
                     breaks = c("koru", "bany", "kibw"),
                     values = c("koru"  = "black",
                                "bany" = "red",
                                "kibw" = "purple"),
                     labels = c("koru"  = "Koru 16",
                                "bany" = "Banyang-Mbo, Cameroon ",
                                "kibw" = "Kibwezi Forest, Kenya")) +
     theme_bw()
  ggsave("whittaker2.pdf", plot = koru_biome, width = 8, height = 6)
  #################
 modern_lma %>% 
  
   ggplot(aes(temperature, precipitation, shape = sites)) +
  geom_point() +
  geom_errorbar(aes(ymin = precipitation - n_error, ymax= precipitation + p_error), width=0.2) +
  geom_errorbarh(aes(xmin= temperature - n_error_h, xmax = temperature + p_error_h), height=0.2) + 
    scale_x_continuous(limits = c(10, 30))
  theme_minimal()

```

###Read data from Miocene Model Intercomparison Project 1 (MioMIP1) dataset (Acosta et al., 2024)

```{r}
#Read_Coordinates
koru_lat <- 0.6012
koru_lon <- 37.3522
# Load libraries
library(ncdf4)

# --- 1. Open NetCDF files ---
ncfile280 <- nc_open()
ncfile400 <- nc_open()
ncfile560 <- nc_open()
ncfile850 <- nc_open()

# Find nearest index function
find_nearest <- function(modelcoords, datacoord) {
  which.min(abs(modelcoords - datacoord))
}

# Load your model lat/lon grid
modellons <- seq(0, 359, length.out = 360)
modellats <- seq(-90, 90, length.out = 181)

# Find nearest model grid point
lon_idx <- find_nearest(modellons, koru_lon)
lat_idx <- find_nearest(modellats, koru_lat)

# Extraction function for Koru MAP
extract_koru_MAP <- function(pr_array) {
  n_exp <- dim(pr_array)[4]  # 8 experiments
  
  koru_vals <- numeric(n_exp)
  
  for (ex in 1:n_exp) {
    pr_monthly <- pr_array[lon_idx, lat_idx, , ex]  # Correct dimension order
    
    if (length(pr_monthly) == 12) {
      koru_annual <- mean(pr_monthly, na.rm = TRUE)  # mean over 12 months
      koru_vals[ex] <- koru_annual
    } else {
      koru_vals[ex] <- NA
    }
  }
  
  return(koru_vals)
}

# Now apply to your arrays
koru_MAP_280 <- extract_koru_MAP(pr280)
koru_MAP_400 <- extract_koru_MAP(pr400)
koru_MAP_560 <- extract_koru_MAP(pr560)
koru_MAP_850 <- extract_koru_MAP(pr850)

# Combine into a data.frame
koru_MAP_summary <- data.frame(
  Experiment = c("MMIO280", "MMIO400", "MMIO560", "MMIO850"),
  Mean_MAP_mm = c(
    mean(koru_MAP_280, na.rm = TRUE),
    mean(koru_MAP_400, na.rm = TRUE),
    mean(koru_MAP_560, na.rm = TRUE),
    mean(koru_MAP_850, na.rm = TRUE)
  )
)

# Print nicely
print(koru_MAP_summary)

```
